
configs:
  flink-conf:
    file: ./conf/flink/config.yaml

  log4j:
    file: ./conf/log4j/log4j.properties
  log4j-console:
    file: ./conf/log4j/log4j-console.properties
  log4j-session:
    file: ./conf/log4j/log4j-session.properties

  postgres_conf:
    file: conf/pg/postgresql.conf
  postgres_hba:
    file: conf/pg/pg_hba.conf

services:
  ################################################################################
  # begin Flink cluster
  #
  # Lots of Jar's added to the base image, Fluss, JDBC, PostgreSQL, Paimon, S3
  ################################################################################
  jobmanager:
    image: ${REPO_NAME}/apacheflink-base-1.20.2-scala_2.12-java17:1.0.1
    hostname: jobmanager
    container_name: jobmanager
    ports:
      - 8084:8081
    environment:
      - ENV_ROOTLOG_LEVEL=DEBUG
      - ENV_FLINKLOG_LEVEL=INFO
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_DEFAULT_REGION=${AWS_REGION}

    volumes:
      - ./creFlinkFlows:/creFlinkFlows
      - ./pyflink:/pyflink

      - ./data/flink/paimon:/paimon
      
      - ./data/flink/logs:/opt/flink/log
      - ./data/flink/checkpoints:/opt/flink/checkpoints
      - ./data/flink/rocksdb:/opt/flink/rocksdb
    configs:
      - source: flink-conf
        target: /opt/flink/conf/config.yaml
      - source: log4j
        target: /opt/flink/conf/log4j.properties
      - source: log4j-console
        target: /opt/flink/conf/log4j-console.properties
      - source: log4j-session
        target: /opt/flink/conf/log4j-session.properties
    command: jobmanager

  taskmanager:
    image: ${REPO_NAME}/apacheflink-base-1.20.2-scala_2.12-java17:1.0.1
    depends_on:
      - jobmanager
    deploy:
      replicas: 1
      resources:
          limits:
            memory: 12G  # Ensure this is higher than taskmanager.memory.process.size
                         # Also make sure this aligns with the config file value specified for the taskmanager => memory.process.size: 12gb 
    environment:
      - ENV_ROOTLOG_LEVEL=INFO
      - ENV_FLINKLOG_LEVEL=INFO
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_DEFAULT_REGION=${AWS_REGION}

    volumes:
      - ./creFlinkFlows:/creFlinkFlows
      - ./pyflink:/pyflink

      - ./data/flink/paimon:/paimon

      - ./data/flink/logs:/opt/flink/log
      - ./data/flink/checkpoints:/opt/flink/checkpoints
      - ./data/flink/rocksdb:/opt/flink/rocksdb
    configs:
      - source: flink-conf
        target: /opt/flink/conf/config.yaml
      - source: log4j
        target: /opt/flink/conf/log4j.properties
      - source: log4j-console
        target: /opt/flink/conf/log4j-console.properties
      - source: log4j-session
        target: /opt/flink/conf/log4j-session.properties
    command: taskmanager


  ################################################################################
  # Will act as a destination store for our JDBC based Flink catalog
  ################################################################################
  postgrescat:
    image: postgres:12
    hostname: ${POSTGRES_CAT_HOST}
    container_name: ${POSTGRES_CAT_HOST}
    restart: unless-stopped
    ports:
      - ${POSTGRES_CAT_PORT}:5432
    environment:
      - POSTGRES_DB=${POSTGRES_CAT_DB}
      - POSTGRES_USER=${POSTGRES_CAT_USER}
      - POSTGRES_PASSWORD=${POSTGRES_CAT_PASSWORD}
    healthcheck:
      test: ["CMD", "psql", "-U", "${POSTGRES_CAT_USER}", "${POSTGRES_CAT_DB}"]
    volumes:
      - ./data/${POSTGRES_CAT_HOST}:/var/lib/postgresql/data
      - ./sql/${POSTGRES_CAT_HOST}:/docker-entrypoint-initdb.d
    configs:
      - source: postgres_conf
        target: /etc/postgresql/postgresql.conf
      - source: postgres_hba
        target: /etc/postgresql/data/pg_hba.conf
    command: -c config_file=/etc/postgresql/postgresql.conf

  ################################################################################
  # Will act as a destination store from where we will CDC our data to be embedded
  ################################################################################
  postgrescdc:
    image: postgres:12
    hostname: ${POSTGRES_CDC_HOST}
    container_name: ${POSTGRES_CDC_HOST}
    restart: unless-stopped
    ports:
      - ${POSTGRES_CDC_PORT}:5432
    environment:
      - POSTGRES_DB=${POSTGRES_CDC_DB}
      - POSTGRES_USER=${POSTGRES_CDC_USER}
      - POSTGRES_PASSWORD=${POSTGRES_CDC_PASSWORD}
    healthcheck:
      test: ["CMD", "psql", "-U", "${POSTGRES_CDC_USER}", "${POSTGRES_CDC_DB}"]
    volumes:
      - ./data/${POSTGRES_CDC_HOST}:/var/lib/postgresql/data
      - ./sql/${POSTGRES_CDC_HOST}:/docker-entrypoint-initdb.d
    configs:
      - source: postgres_conf
        target: /etc/postgresql/postgresql.conf
      - source: postgres_hba
        target: /etc/postgresql/data/pg_hba.conf
    command: -c config_file=/etc/postgresql/postgresql.conf
  ################################################################################


################################################################################
# Without a network explicitly defined, you hit this Hive/Thrift error
# java.net.URISyntaxException Illegal character in hostname
# https://github.com/TrivadisPF/platys-modern-data-platform/issues/231
networks:
  default:
    name: ${COMPOSE_PROJECT_NAME}